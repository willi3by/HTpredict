{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.layers import Input, Conv3D, BatchNormalization, Activation, Add, GlobalAveragePooling3D, Dense, Dropout, Masking\n",
    "from tensorflow.keras.models import Model\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "from scipy.ndimage import zoom\n",
    "import matplotlib.pyplot as plt\n",
    "from tf_keras_vis.saliency import Saliency\n",
    "from tf_keras_vis.scorecam import ScoreCAM\n",
    "from tf_keras_vis.gradcam_plus_plus import GradcamPlusPlus\n",
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
    "from tf_keras_vis.utils.scores import CategoricalScore\n",
    "import ants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rician_noise(image, mask):\n",
    "    noise_level = np.random.uniform(low=0.1, high=0.5, size=(1,))\n",
    "    noise_real = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=noise_level)\n",
    "    noise_imag = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=noise_level)\n",
    "    noisy_image = tf.sqrt(tf.square(image + noise_real) + tf.square(noise_imag))\n",
    "    noisy_image = tf.multiply(noisy_image, tf.cast(mask[...,np.newaxis], tf.float32))\n",
    "    return noisy_image\n",
    "\n",
    "\n",
    "def augment_image_3d(image, mask):\n",
    "    image = add_rician_noise(image, mask)\n",
    "    return image\n",
    "\n",
    "# Function to augment dataset\n",
    "def augment_dataset(images, labels, mask, positive_augmentation_factor=2):\n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        image = images[i]\n",
    "        label = labels[i]\n",
    "        \n",
    "        if label == 1:\n",
    "            for _ in range(positive_augmentation_factor):\n",
    "                augmented_image = augment_image_3d(image, mask)\n",
    "                augmented_images.append(augmented_image)\n",
    "                augmented_labels.append(label)\n",
    "            \n",
    "        augmented_image = augment_image_3d(image, mask)\n",
    "        augmented_images.append(augmented_image)\n",
    "        augmented_labels.append(label)\n",
    "    \n",
    "    return np.array(augmented_images), np.array(augmented_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, filters, kernel_size, strides=(1, 1, 1), padding='same'):\n",
    "    x = Conv3D(filters, kernel_size, strides=strides, padding=padding)(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def identity_block(input_tensor, filters, kernel_size):\n",
    "    x = Conv3D(filters, kernel_size, padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv3D(filters, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Add()([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv_identity_block(input_tensor, filters, kernel_size, strides=(2, 2, 2)):\n",
    "    x = Conv3D(filters, kernel_size, strides=strides, padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv3D(filters, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    shortcut = Conv3D(filters, kernel_size=(1, 1, 1), strides=strides, padding='same')(input_tensor)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def resnet_3d(input_shape, dropout_rate=0.5):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    mask = Masking(mask_value=0.0)(input_layer)\n",
    "    x = conv_block(mask, 64, (7, 7, 7), strides=(2, 2, 2))\n",
    "    \n",
    "    x = conv_identity_block(x, 64, (3, 3, 3))\n",
    "    for _ in range(3):\n",
    "        x = identity_block(x, 64, (3, 3, 3))\n",
    "    \n",
    "    x = conv_identity_block(x, 128, (3, 3, 3), strides=(2, 2, 2))\n",
    "    for _ in range(4):\n",
    "        x = identity_block(x, 128, (3, 3, 3))\n",
    "    \n",
    "    x = conv_identity_block(x, 256, (3, 3, 3), strides=(2, 2, 2))\n",
    "    for _ in range(6):\n",
    "        x = identity_block(x, 256, (3, 3, 3))\n",
    "    \n",
    "    x = conv_identity_block(x, 512, (3, 3, 3), strides=(2, 2, 2))\n",
    "    for _ in range(3):\n",
    "        x = identity_block(x, 512, (3, 3, 3))\n",
    "    \n",
    "    x = GlobalAveragePooling3D()(x)\n",
    "    x = Dropout(rate=dropout_rate)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape and number of classes\n",
    "input_shape = (64, 82, 32, 1)  # Example input shape for 3D data\n",
    "batch_size = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ants.image_read('CT_template_resamp.nii')\n",
    "template_mask = np.where(template.numpy() > 0, 1.0, 0.0)\n",
    "bad_subj = [5, 28, 29, 30, 43, 65, 66, 70, 89, 94, 99, 101, 102, 112, 116, 118, 119, 134, 135, 138, 151]\n",
    "x_arr = np.load('x_arr.npy')\n",
    "y_arr = np.load('y_arr.npy')\n",
    "x_arr = np.array([a for i,a in enumerate(x_arr) if i not in bad_subj])\n",
    "y_arr = np.array([a for i,a in enumerate(y_arr) if i not in bad_subj])\n",
    "x_resamp = []\n",
    "for i in range(x_arr.shape[0]):\n",
    "    subj_windowed = np.clip(x_arr[i], 10, 100)[32:96, 22:104,  28:60]\n",
    "    subj_norm = (subj_windowed - subj_windowed.min())/(subj_windowed.max() - subj_windowed.min())\n",
    "    subj_masked = subj_norm * template_mask[32:96, 22:104,  28:60]\n",
    "    x_resamp.append(subj_masked)\n",
    "x_arr = np.stack(x_resamp, axis=0)\n",
    "bad_subj_2 = [41,42,44,59, 75, 86, 92, 97, 98, 99, 105, 108, 109, 110, 111, 116, 121,125,128, 131, 135, 139]\n",
    "x_arr = np.array([a for i,a in enumerate(x_arr) if i not in bad_subj_2])\n",
    "y_arr = np.array([a for i,a in enumerate(y_arr) if i not in bad_subj_2])\n",
    "x_arr = x_arr[...,np.newaxis]\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_arr, y_arr, random_state=40, test_size=0.2, stratify=y_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_for_0 = (1 / (len(y_train)-y_train.sum())) * (y_train.shape[0] / 2.0)\n",
    "weight_for_1 = (1 / y_train.sum()) * (y_train.shape[0] / 2.0)\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=42).split(x_arr, y_arr))\n",
    "auc_per_fold = []\n",
    "loss_per_fold = []\n",
    "for j, (train_idx, val_idx) in enumerate(folds):\n",
    "    #Split data\n",
    "    x_train_cv = x_arr[train_idx]\n",
    "    y_train_cv = y_arr[train_idx]\n",
    "    x_val_cv = x_arr[val_idx]\n",
    "    y_val_cv = y_arr[val_idx]\n",
    "    \n",
    "    \n",
    "    # Create the model\n",
    "    model = resnet_3d(input_shape, dropout_rate=0.3)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Nadam(learning_rate=0.0001), loss=tf.keras.losses.BinaryFocalCrossentropy(), metrics=tf.keras.metrics.AUC())\n",
    "    filepath = \"best_model_weights_\" + str(j) + \".h5\"\n",
    "    if j == 0:\n",
    "        monitor_val = 'val_auc'\n",
    "    else:\n",
    "        monitor_val = 'val_auc_' + str(j)\n",
    "    weight_for_0 = (1 / (len(y_train_cv)-y_train_cv.sum())) * (y_train_cv.shape[0] / 2.0)\n",
    "    weight_for_1 = (1 / y_train_cv.sum()) * (y_train_cv.shape[0] / 2.0)\n",
    "    cv_class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "    history = model.fit(x_train_cv, y_train_cv, validation_data=(x_val_cv, y_val_cv), \n",
    "                    batch_size=batch_size, epochs=120, class_weight=cv_class_weight, \n",
    "                    callbacks=[tf.keras.callbacks.ModelCheckpoint(filepath = filepath, monitor=monitor_val,\n",
    "                                                                 mode = \"max\", save_weights_only=True, save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style for the plot\n",
    "sns.set(style=\"whitegrid\")\n",
    "colors = sns.color_palette(\"husl\", 5) \n",
    "folds = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=42).split(x_arr, y_arr))\n",
    "auc_per_fold = []\n",
    "loss_per_fold = []\n",
    "for j, (train_idx, val_idx) in enumerate(folds):\n",
    "    #Split data\n",
    "    x_train_cv = x_arr[train_idx]\n",
    "    y_train_cv = y_arr[train_idx]\n",
    "    x_val_cv = x_arr[val_idx]\n",
    "    y_val_cv = y_arr[val_idx]\n",
    "    \n",
    "    # Create the model\n",
    "    model = resnet_3d(input_shape, dropout_rate=0.3)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Nadam(learning_rate=0.0001), loss=tf.keras.losses.BinaryFocalCrossentropy(), metrics=tf.keras.metrics.AUC())\n",
    "    batch_size=12\n",
    "    filepath = \"best_model_weights_\" + str(j) + \".h5\"\n",
    "    weight_for_0 = (1 / (len(y_train_cv)-y_train_cv.sum())) * (y_train_cv.shape[0] / 2.0)\n",
    "    weight_for_1 = (1 / y_train_cv.sum()) * (y_train_cv.shape[0] / 2.0)\n",
    "    cv_class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "    model.load_weights(filepath)\n",
    "    results = model.predict(x_val_cv)\n",
    "        # Calculate ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_val_cv, results)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Plot ROC curve for the current fold\n",
    "    plt.plot(fpr, tpr, color=colors[j], lw=3, label=f'Fold {j + 1} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# Plot diagonal line\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', lw=2)\n",
    "\n",
    "# Customize plot details\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=14)\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.title('ROC Curve for Each Fold', fontsize=16, weight='bold')\n",
    "plt.legend(loc='lower right', fontsize=12)\n",
    "plt.grid(True, linestyle='--', linewidth=0.7, alpha=0.7)\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "plt.savefig('roc_curve_plot.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(x_val, y_val, batch_size=12)\n",
    "predictions = model.predict(x_val)\n",
    "ht_example_correct = x_val_cv[17] #Hand selected examples\n",
    "ht_example_incorrect = x_val_cv[0] #Hand selected examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency = Saliency(model, model_modifier=ReplaceToLinear(), clone=True)\n",
    "saliency_map_correct = saliency(CategoricalScore([0]), ht_example_correct)\n",
    "saliency_map_incorrect = saliency(CategoricalScore([0]), ht_example_incorrect)\n",
    "template_resamp = ants.image_read('CT_template_resamp.nii')\n",
    "x_correct_ants = ants.copy_image_info(template_resamp, ants.from_numpy(ht_example_correct.squeeze()))\n",
    "x_incorrect_ants = ants.copy_image_info(template_resamp, ants.from_numpy(ht_example_incorrect.squeeze()))\n",
    "sal_correct_ants = ants.copy_image_info(template_resamp, ants.from_numpy(saliency_map_correct.squeeze()))\n",
    "sal_incorrect_ants = ants.copy_image_info(template_resamp, ants.from_numpy(saliency_map_incorrect.squeeze()))\n",
    "sal_correct_smooth = sal_correct_ants.smooth_image(3)\n",
    "sal_correct_norm = (sal_correct_smooth - sal_correct_smooth.mean())/sal_correct_smooth.std()\n",
    "sal_incorrect_smooth = sal_incorrect_ants.smooth_image(3)\n",
    "sal_incorrect_norm = (sal_incorrect_smooth - sal_incorrect_smooth.mean())/sal_incorrect_smooth.std()\n",
    "sal_diff = sal_correct_norm - sal_incorrect_norm\n",
    "ants.image_write(x_correct_ants, 'ht_example_correct.nii')\n",
    "ants.image_write(sal_correct_norm, 'sal_example_correct.nii')\n",
    "ants.image_write(x_incorrect_ants, 'ht_example_incorrect.nii')\n",
    "ants.image_write(sal_incorrect_norm, 'sal_example_incorrect.nii')\n",
    "ants.image_write(sal_diff, 'sal_example_diff.nii')\n",
    "template_mask = ants.image_read('template_reduced_mask.nii')\n",
    "sal_diff_masked = sal_diff*template_mask\n",
    "ants.image_write(sal_diff_masked, 'sal_example_diff_masked.nii')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
